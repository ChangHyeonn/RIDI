#!/usr/bin/env python3
"""
Voice Chat Pipeline - STT + LLM + TTS í†µí•© ìŒì„± ëŒ€í™” ì‹œìŠ¤í…œ
ìŒì„± ì…ë ¥ â†’ í…ìŠ¤íŠ¸ ë³€í™˜ â†’ AI ì‘ë‹µ â†’ ìŒì„± ì¶œë ¥
"""

import sys
import os
import time
import logging
import tempfile
import soundfile as sf
import numpy as np
from datetime import datetime
from typing import Dict, Any, Optional
from dotenv import load_dotenv

# AI ëª¨ë“ˆ import
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'Models'))
from Models.STT import WhisperSTT
from Models.LLM import LLMFactory
from Models.TTS import TTS

class VoiceChatPipeline:
    """ìŒì„± ëŒ€í™” íŒŒì´í”„ë¼ì¸"""
    
    def __init__(self, 
                 stt_model: str = "small",
                 llm_type: str = None,  # "gpt" or "gemini", Noneì´ë©´ .envì—ì„œ ê°€ì ¸ì˜´
                 device: str = "auto"):
        # .env íŒŒì¼ ë¡œë“œ
        load_dotenv()
        
        self.device = self._get_device(device)
        self.llm_type = llm_type or os.getenv('LLM_MODEL', 'gemini')
        
        self._setup_logging()
        self._initialize_components(stt_model)
        self.logger.info(f"Voice Chat Pipeline initialized successfully on {self.device}")
    
    def _get_device(self, device: str) -> str:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ìµœì ì˜ device ì„ íƒ"""
        if device == "auto":
            import torch
            if torch.cuda.is_available():
                return "cuda"
            else:
                return "cpu"
        return device
    
    def _setup_logging(self):
        """ë¡œê¹… ì„¤ì •"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        self.logger = logging.getLogger(__name__)
    
    def _initialize_components(self, stt_model: str):
        """AI ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”"""
        self.logger.info("Initializing AI components...")
        
        # STT ì´ˆê¸°í™”
        self.stt = WhisperSTT(model_name=stt_model, device=self.device)
        self.stt.optimize_for_korean(True)
        
        # LLM ì´ˆê¸°í™” (GPT/Gemini ì„ íƒ ê°€ëŠ¥)
        self.llm = LLMFactory.create_llm(self.llm_type)
        
        # TTS ì´ˆê¸°í™”
        self.tts = TTS()
        
        self.logger.info("All AI components initialized successfully")
    
    def chat_with_voice(self, audio_input_path: str) -> Dict[str, Any]:
        """
        ìŒì„±ìœ¼ë¡œ ëŒ€í™”í•˜ëŠ” ë©”ì¸ í•¨ìˆ˜
        
        Args:
            audio_input_path: ì…ë ¥ ìŒì„± íŒŒì¼ ê²½ë¡œ
            
        Returns:
            Dict[str, Any]: ëŒ€í™” ê²°ê³¼
        """
        start_time = time.time()
        
        try:
            self.logger.info(f"Starting voice chat with: {audio_input_path}")
            
            # Step 1: STT (ìŒì„± â†’ í…ìŠ¤íŠ¸)
            user_message = self._process_stt(audio_input_path)
            if not user_message:
                return self._create_error_response("ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
            # Step 2: LLM (í…ìŠ¤íŠ¸ â†’ AI ì‘ë‹µ)
            ai_response = self._process_llm(user_message)
            
            # Step 3: TTS (AI ì‘ë‹µ â†’ ìŒì„±)
            audio_response = self._process_tts(ai_response)
            
            total_time = time.time() - start_time
            
            return self._create_success_response(
                user_message, ai_response, audio_response, total_time
            )
            
        except Exception as e:
            self.logger.error(f"Voice chat failed: {e}")
            return self._create_error_response(str(e))
    
    def _process_stt(self, audio_path: str) -> str:
        """STT ì²˜ë¦¬"""
        self.logger.info("Processing STT...")
        transcribed_text = self.stt.transcribe(audio_path, use_preprocessing=True)
        self.logger.info(f"STT ê²°ê³¼: {transcribed_text}")
        return transcribed_text
    
    def _process_llm(self, user_message: str) -> str:
        """LLM ì²˜ë¦¬"""
        self.logger.info("Processing LLM...")
        
        # ëŒ€í™”í˜• í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        conversation_prompt = f"""
ë‹¹ì‹ ì€ ì¹œê·¼í•˜ê³  ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ë©”ì‹œì§€ì— ëŒ€í•´ ìì—°ìŠ¤ëŸ½ê³  ìœ ìš©í•œ ì‘ë‹µì„ ì œê³µí•˜ì„¸ìš”.

ì‚¬ìš©ì: {user_message}
AI: """
        
        llm_response = self.llm.generate_response(conversation_prompt)
        self.logger.info(f"LLM ì‘ë‹µ: {llm_response}")
        return llm_response
    
    def _process_tts(self, text: str) -> bytes:
        """TTS ì²˜ë¦¬"""
        self.logger.info("Processing TTS...")
        audio_response = self.tts.generate_from_llm_response(text)
        self.logger.info("TTS ì™„ë£Œ")
        return audio_response
    
    def _create_success_response(self, user_message: str, ai_response: str, 
                               audio_response: bytes, total_time: float) -> Dict[str, Any]:
        """ì„±ê³µ ì‘ë‹µ ìƒì„±"""
        return {
            "success": True,
            "user_message": user_message,
            "ai_response": ai_response,
            "audio_response": audio_response,
            "processing_time": total_time,
            "timestamp": datetime.now().isoformat(),
            "model_info": {
                "stt_model": self.stt.model_name,
                "llm_type": self.llm_type,
                "tts_model": self.tts.model_name
            }
        }
    
    def _create_error_response(self, error_message: str) -> Dict[str, Any]:
        """ì—ëŸ¬ ì‘ë‹µ ìƒì„±"""
        return {
            "success": False,
            "error": error_message,
            "timestamp": datetime.now().isoformat()
        }
    
    def get_pipeline_info(self) -> Dict[str, Any]:
        """íŒŒì´í”„ë¼ì¸ ì •ë³´ ë°˜í™˜"""
        return {
            "device": self.device,
            "llm_type": self.llm_type,
            "components": {
                "stt": self.stt.get_model_info(),
                "llm": self.llm.get_model_info(),
                "tts": self.tts.get_model_info()
            }
        }
    
    def change_llm_model(self, llm_type: str):
        """LLM ëª¨ë¸ ë³€ê²½"""
        self.logger.info(f"Changing LLM model to: {llm_type}")
        self.llm_type = llm_type
        self.llm = LLMFactory.create_llm(llm_type)
        self.logger.info(f"LLM model changed successfully to {llm_type}")

def main():
    """í…ŒìŠ¤íŠ¸ìš© ë©”ì¸ í•¨ìˆ˜"""
    # .env íŒŒì¼ì—ì„œ API í‚¤ì™€ ëª¨ë¸ ì„¤ì •ì„ ìë™ìœ¼ë¡œ ê°€ì ¸ì˜´
    
    # íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”
    pipeline = VoiceChatPipeline(
        stt_model="small",
        llm_type=None,  # .env íŒŒì¼ì—ì„œ ìë™ìœ¼ë¡œ ê°€ì ¸ì˜´
        device="auto"
    )
    
    # íŒŒì´í”„ë¼ì¸ ì •ë³´ ì¶œë ¥
    info = pipeline.get_pipeline_info()
    print("ğŸ¤ Voice Chat Pipeline Info:")
    print(f"Device: {info['device']}")
    print(f"LLM Type: {info['llm_type']}")
    print(f"STT Model: {info['components']['stt']['model_name']}")
    print(f"TTS Model: {info['components']['tts']['model_name']}")
    
    # í…ŒìŠ¤íŠ¸ (ì‹¤ì œ ìŒì„± íŒŒì¼ì´ í•„ìš”)
    # result = pipeline.chat_with_voice("test_audio.wav")
    # if result['success']:
    #     print(f"ì‚¬ìš©ì: {result['user_message']}")
    #     print(f"AI: {result['ai_response']}")
    #     print(f"ì²˜ë¦¬ ì‹œê°„: {result['processing_time']:.2f}ì´ˆ")
    # else:
    #     print(f"ì˜¤ë¥˜: {result['error']}")

if __name__ == "__main__":
    main() 