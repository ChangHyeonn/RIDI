# STT 성능 테스트

이 폴더는 STT(Speech-to-Text) 모델의 성능을 다양한 device 환경에서 테스트하기 위한 스크립트들을 포함합니다.

## 📁 파일 구조

```
test_folder/
├── stt_performance_test.py    # STT 성능 테스트 메인 스크립트
├── create_test_audio.py       # 테스트용 음성 파일 생성
├── README.md                  # 이 파일
└── stt_performance_results.json  # 테스트 결과 (자동 생성)
```

## 🚀 사용법

### 1. 테스트용 음성 파일 생성

```bash
cd test_folder
python create_test_audio.py
```

이 스크립트는 4개의 한국어 테스트 음성 파일을 생성합니다:
- `test_audio_1.mp3`: "안녕하세요. 오늘 날씨가 정말 좋네요."
- `test_audio_2.mp3`: "내일 오후 3시에 병원 예약이 있습니다."
- `test_audio_3.mp3`: "주말에 가족들과 함께 저녁 식사를 할 예정입니다."
- `test_audio_4.mp3`: "다음 주 월요일부터 새로운 프로젝트를 시작합니다."

### 2. STT 성능 테스트 실행

```bash
python stt_performance_test.py
```

이 스크립트는 다음을 수행합니다:

1. **사용 가능한 device 확인**
   - CUDA (NVIDIA GPU)
   - CPU (기본값)
   - ⚠️ MPS는 Whisper 모델과 호환성 문제로 제외

2. **각 device에서 STT 성능 테스트**
   - 모델 초기화 시간
   - 음성 변환 시간
   - 총 처리 시간
   - 메모리 사용량

3. **성능 비교 및 분석**
   - 가장 빠른 device
   - 성능 순위
   - 성능 개선율

## 📊 테스트 결과 예시

```
================================================================================
📊 STT 성능 테스트 결과
================================================================================
🎵 음성 파일: test_audio_1.mp3
🤖 모델: small
⏰ 테스트 시간: 2024-01-15 14:30:25

📈 개별 성능 결과:
--------------------------------------------------------------------------------

🔧 CUDA 환경:
  ✅ 초기화 시간: 1.23초
  ✅ 변환 시간: 0.45초
  ✅ 총 시간: 1.68초
  💾 메모리: {'allocated': '2.34 GB', 'cached': '3.12 GB', 'total': '8.00 GB'}
  📝 변환 결과: 안녕하세요. 오늘 날씨가 정말 좋네요...

🔧 CPU 환경:
  ✅ 초기화 시간: 1.89초
  ✅ 변환 시간: 3.45초
  ✅ 총 시간: 5.34초
  💾 메모리: {'info': 'CPU memory', 'note': 'System RAM usage'}
  📝 변환 결과: 안녕하세요. 오늘 날씨가 정말 좋네요...

🏆 성능 비교:
--------------------------------------------------------------------------------
🥇 가장 빠른 device: CUDA
⏱️  최고 기록: 1.68초

📊 성능 순위:
  1. CUDA: 1.68초 (+0.00초)
  2. CPU: 5.34초 (+3.66초)

📈 성능 개선율:
  CPU: 68.5% 느림
================================================================================
```

## 🔧 환경별 특징

### 🎮 CUDA (NVIDIA GPU)
- **장점**: 가장 빠른 성능
- **단점**: NVIDIA GPU 필요
- **사용 시**: 실사용 환경에서 권장

### 💻 CPU
- **장점**: 모든 환경에서 사용 가능
- **단점**: 상대적으로 느린 성능
- **사용 시**: 개발 환경 및 안전한 대안

### ⚠️ MPS (Apple Silicon)
- **상태**: Whisper 모델과 호환성 문제로 제외
- **이유**: `aten::_sparse_coo_tensor_with_dims_and_tensors` 연산 미지원
- **해결책**: CPU 사용 권장

## 📈 예상 성능

| Device | 초기화 시간 | 변환 시간 | 총 시간 | 메모리 사용량 |
|--------|-------------|-----------|---------|---------------|
| CUDA   | 1-2초      | 0.5-1초   | 1.5-3초 | 2-4GB         |
| CPU    | 1-2초      | 3-5초     | 4-7초   | 1-2GB         |

## 🛠️ 문제 해결

### 1. 모듈 import 오류
```bash
# AI 폴더의 Models를 Python path에 추가
export PYTHONPATH="${PYTHONPATH}:/path/to/RIDI/AI/Models"
```

### 2. 음성 파일 없음
```bash
# 테스트용 음성 파일 생성
python create_test_audio.py
```

### 3. MPS 호환성 문제
- **문제**: Whisper 모델이 MPS에서 지원되지 않는 연산 사용
- **해결책**: CPU 사용 (안정적이고 호환성 보장)
- **대안**: CUDA 사용 (가장 빠른 성능)

## 📝 결과 저장

테스트 결과는 `stt_performance_results.json` 파일에 자동으로 저장됩니다. 이 파일에는 다음 정보가 포함됩니다:

- 테스트 정보 (파일, 모델, 시간)
- 각 device별 상세 결과
- 성능 비교 분석

이 파일을 통해 나중에 결과를 다시 분석하거나 다른 도구로 시각화할 수 있습니다. 